{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy - Machine Learning</font>\n",
    "\n",
    "# <font color='blue'>Capítulo 8 - Affinity Propagation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****** Este Jupyter Notebook foi atualizado para a versão 3.6.1. da Linguagem Python em 05/07/2017 ******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AffinityPropagation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Affinity Propagation é um algoritmo de Clustering relativamente novo baseado no conceito de \"passagem de mensagens\" entre pontos de dados. O AP não requer que o número de clusters seja determinado ou estimado antes de executar o algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você identificaria um pequeno número de imagens de rostos que juntos representam com precisão um conjunto de dados de imagens de rosto? Como você identificaria um pequeno número de sentenças que refletem com precisão o conteúdo de um documento? Como você identificaria um pequeno número de cidades que são mais facilmente acessíveis de todas as outras cidades por companhia aérea comercial? Como você identificaria segmentos de DNA que refletissem as propriedades de expressão dos genes? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Affinity Propagation é um algoritmo que toma como medida de entrada a semelhança entre pares de pontos de dados e simultaneamente considera todos os pontos de dados como potenciais exemplares. Mensagens são trocadas entre os pontos de dados até que um conjunto de alta qualidade de exemplares e clusters correspondentes, gradualmente emerge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos o Affinity Propagation para resolver uma variedade de problemas de agrupamento com erros muito menores do que os encontrados por outros métodos, o que ocorre geralmente em menos de um centésimo do tempo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo define a afinidade dos pontos de dados alternando duas etapas de passagem de mensagem, para atualizar duas matrizes: a matriz de responsabilidade (R) e a matriz de disponibilidade (A). O Affinity Propagation cria clusters enviando mensagens entre pares de amostras até convergência. Um conjunto de dados é então descrito utilizando um pequeno número de exemplares, que são identificados como os mais representativos de outras amostras. As mensagens enviadas entre pares representam a adequação para uma amostra ser o exemplar da outra, que é atualizada em resposta aos valores de outros pares. Esta atualização acontece iterativamente até a convergência, altura em que os exemplares finais são escolhidos, e, portanto, o agrupamento final é dado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Affinity Propagation pode ser interessante, pois ele escolhe o número de clusters com base nos dados fornecidos. Para este efeito, os dois parâmetros importantes são a preferência, que controla quantos exemplares são utilizados, e o factor de amortecimento (damping factor). A principal desvantagem de Affinity Propagation é a sua complexidade. Isso torna o algoritmo mais apropriado para pequenos e médios conjuntos de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gerando conjunto de dados\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "X, labels_true = make_blobs(n_samples = 300, centers = centers, cluster_std = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criação do modelo\n",
    "af = AffinityPropagation(preference = -50).fit(X)\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "labels = af.labels_\n",
    "\n",
    "n_clusters_ = len(cluster_centers_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Métricas\n",
    "# Homogeneity: cada cluster contém apenas membros de uma única classe\n",
    "# Completeness: todos os membros de uma classe estão atribuídos ao mesmo cluster\n",
    "# V-measure: média harmônica entre os 2 anteriores\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print(\"Homogeneidade: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completude: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "print(\"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(X, labels, metric = 'sqeuclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.close('all')\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "\n",
    "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "for k, col in zip(range(n_clusters_), colors):\n",
    "    class_members = labels == k\n",
    "    cluster_center = X[cluster_centers_indices[k]]\n",
    "    plt.plot(X[class_members, 0], X[class_members, 1], col + '.')\n",
    "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor = col, markeredgecolor = 'k', markersize = 14)\n",
    "    for x in X[class_members]:\n",
    "        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\n",
    "\n",
    "plt.title('Número Estimado de Clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import cluster, covariance, manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtém as cotações históricas do Yahoo\n",
    "try:\n",
    "     from matplotlib.finance import quotes_historical_yahoo_ochl\n",
    "except ImportError:\n",
    "     from matplotlib.finance import quotes_historical_yahoo as quotes_historical_yahoo_ochl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definindo o período para coleta das cotações\n",
    "d1 = datetime.datetime(2003, 1, 1)\n",
    "d2 = datetime.datetime(2008, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dicionário de símbolos para as cotações de algumas empresas\n",
    "symbol_dict = {\n",
    "    'TOT': 'Total',\n",
    "    'XOM': 'Exxon',\n",
    "    'CVX': 'Chevron',\n",
    "    'COP': 'ConocoPhillips',\n",
    "    'VLO': 'Valero Energy',\n",
    "    'MSFT': 'Microsoft',\n",
    "    'IBM': 'IBM',\n",
    "    'TWX': 'Time Warner',\n",
    "    'CMCSA': 'Comcast',\n",
    "    'CVC': 'Cablevision',\n",
    "    'YHOO': 'Yahoo',\n",
    "    'DELL': 'Dell',\n",
    "    'HPQ': 'HP',\n",
    "    'AMZN': 'Amazon',\n",
    "    'TM': 'Toyota',\n",
    "    'CAJ': 'Canon',\n",
    "    'MTU': 'Mitsubishi',\n",
    "    'SNE': 'Sony',\n",
    "    'F': 'Ford',\n",
    "    'HMC': 'Honda',\n",
    "    'NAV': 'Navistar',\n",
    "    'NOC': 'Northrop Grumman',\n",
    "    'BA': 'Boeing',\n",
    "    'KO': 'Coca Cola',\n",
    "    'MMM': '3M',\n",
    "    'MCD': 'Mc Donalds',\n",
    "    'PEP': 'Pepsi',\n",
    "    'MDLZ': 'Kraft Foods',\n",
    "    'K': 'Kellogg',\n",
    "    'UN': 'Unilever',\n",
    "    'MAR': 'Marriott',\n",
    "    'PG': 'Procter Gamble',\n",
    "    'CL': 'Colgate-Palmolive',\n",
    "    'GE': 'General Electrics',\n",
    "    'WFC': 'Wells Fargo',\n",
    "    'JPM': 'JPMorgan Chase',\n",
    "    'AIG': 'AIG',\n",
    "    'AXP': 'American express',\n",
    "    'BAC': 'Bank of America',\n",
    "    'GS': 'Goldman Sachs',\n",
    "    'AAPL': 'Apple',\n",
    "    'SAP': 'SAP',\n",
    "    'CSCO': 'Cisco',\n",
    "    'TXN': 'Texas instruments',\n",
    "    'XRX': 'Xerox',\n",
    "    'LMT': 'Lookheed Martin',\n",
    "    'WMT': 'Wal-Mart',\n",
    "    'WBA': 'Walgreen',\n",
    "    'HD': 'Home Depot',\n",
    "    'GSK': 'GlaxoSmithKline',\n",
    "    'PFE': 'Pfizer',\n",
    "    'SNY': 'Sanofi-Aventis',\n",
    "    'NVS': 'Novartis',\n",
    "    'KMB': 'Kimberly-Clark',\n",
    "    'R': 'Ryder',\n",
    "    'GD': 'General Dynamics',\n",
    "    'RTN': 'Raytheon',\n",
    "    'CVS': 'CVS',\n",
    "    'CAT': 'Caterpillar',\n",
    "    'DD': 'DuPont de Nemours'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Array dos itens do dicionário\n",
    "symbols, names = np.array(list(symbol_dict.items())).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Usando List Comprehension para obter as cotações\n",
    "quotes = [quotes_historical_yahoo_ochl(symbol, d1, d2, asobject = True) for symbol in symbols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Valor das cotações abertura e encerramento\n",
    "open = np.array([q.open for q in quotes]).astype(np.float)\n",
    "close = np.array([q.close for q in quotes]).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variação diária\n",
    "variation = close - open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edge_model = covariance.GraphLassoCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Padronizando a série temporal. \n",
    "# Usando correlação ao invés de covariância, pois aumenta a eficiência da estrutura de dados\n",
    "X = variation.copy().T\n",
    "X /= X.std(axis=0)\n",
    "edge_model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criando o modelo AP\n",
    "_, labels = cluster.affinity_propagation(edge_model.covariance_)\n",
    "n_labels = labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imprimindo os clusters gerados\n",
    "for i in range(n_labels + 1):\n",
    "    print('Cluster %i: %s' % ((i + 1), ', '.join(names[labels == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reduzindo a dimensionalidade\n",
    "node_position_model = manifold.LocallyLinearEmbedding(n_components = 2, eigen_solver = 'dense', n_neighbors = 6)\n",
    "embedding = node_position_model.fit_transform(X.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(1, facecolor = 'w', figsize = (10, 8))\n",
    "plt.clf()\n",
    "ax = plt.axes([0., 0., 1., 1.])\n",
    "plt.axis('off')\n",
    "\n",
    "# Gráfico com correlações parciais\n",
    "partial_correlations = edge_model.precision_.copy()\n",
    "d = 1 / np.sqrt(np.diag(partial_correlations))\n",
    "partial_correlations *= d\n",
    "partial_correlations *= d[:, np.newaxis]\n",
    "non_zero = (np.abs(np.triu(partial_correlations, k=1)) > 0.02)\n",
    "\n",
    "# Plot dos nodes\n",
    "plt.scatter(embedding[0], embedding[1], s=100 * d ** 2, c=labels, cmap=plt.cm.spectral)\n",
    "\n",
    "# Plot dos edges\n",
    "start_idx, end_idx = np.where(non_zero)\n",
    "\n",
    "# Segmentos\n",
    "segments = [[embedding[:, start], embedding[:, stop]] for start, stop in zip(start_idx, end_idx)]\n",
    "values = np.abs(partial_correlations[non_zero])\n",
    "lc = LineCollection(segments,\n",
    "                    zorder=0, cmap=plt.cm.hot_r,\n",
    "                    norm=plt.Normalize(0, .7 * values.max()))\n",
    "lc.set_array(values)\n",
    "lc.set_linewidths(15 * values)\n",
    "ax.add_collection(lc)\n",
    "\n",
    "# Adicionando Labels\n",
    "for index, (name, label, (x, y)) in enumerate(\n",
    "        zip(names, labels, embedding.T)):\n",
    "\n",
    "    dx = x - embedding[0]\n",
    "    dx[index] = 1\n",
    "    dy = y - embedding[1]\n",
    "    dy[index] = 1\n",
    "    this_dx = dx[np.argmin(np.abs(dy))]\n",
    "    this_dy = dy[np.argmin(np.abs(dx))]\n",
    "    if this_dx > 0:\n",
    "        horizontalalignment = 'left'\n",
    "        x = x + .002\n",
    "    else:\n",
    "        horizontalalignment = 'right'\n",
    "        x = x - .002\n",
    "    if this_dy > 0:\n",
    "        verticalalignment = 'bottom'\n",
    "        y = y + .002\n",
    "    else:\n",
    "        verticalalignment = 'top'\n",
    "        y = y - .002\n",
    "    plt.text(x, y, name, size=10,\n",
    "             horizontalalignment=horizontalalignment,\n",
    "             verticalalignment=verticalalignment,\n",
    "             bbox=dict(facecolor='w',\n",
    "                       edgecolor=plt.cm.spectral(label / float(n_labels)),\n",
    "                       alpha=.6))\n",
    "\n",
    "plt.xlim(embedding[0].min() - .15 * embedding[0].ptp(),\n",
    "         embedding[0].max() + .10 * embedding[0].ptp(),)\n",
    "plt.ylim(embedding[1].min() - .03 * embedding[1].ptp(),\n",
    "         embedding[1].max() + .03 * embedding[1].ptp())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obrigado - Data Science Academy - <a href=http://facebook.com/dsacademy>facebook.com/dsacademybr</a>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
