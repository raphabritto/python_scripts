{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy - Machine Learning</font>\n",
    "\n",
    "# <font color='blue'>Capítulo 12 - Deep Learning</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****** Este Jupyter Notebook foi atualizado para a versão 3.6.1. da Linguagem Python em 05/07/2017 ******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras é uma biblioteca para rede neural de alto-nível escrita em Python e roda como frontend em TensorFlow ou Theano. O bom disso é que você pode substituir uma rede neural por outra utilizando Keras. Ela foi desenvolvida para facilitar experimentações rápidas, isto é, sem que você tenha que dominar cada um dos backgrounds, de maneira rápida e eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: theano in /Users/dmpm/anaconda/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/dmpm/anaconda/lib/python3.6/site-packages (from theano)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/dmpm/anaconda/lib/python3.6/site-packages (from theano)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/dmpm/anaconda/lib/python3.6/site-packages (from theano)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/dmpm/anaconda/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: numpy>=1.11.0 in /Users/dmpm/anaconda/lib/python3.6/site-packages (from tensorflow)\r\n",
      "Requirement already satisfied: protobuf>=3.2.0 in /Users/dmpm/anaconda/lib/python3.6/site-packages (from tensorflow)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /Users/dmpm/anaconda/lib/python3.6/site-packages (from tensorflow)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/dmpm/anaconda/lib/python3.6/site-packages (from tensorflow)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/dmpm/anaconda/lib/python3.6/site-packages (from tensorflow)\r\n",
      "Requirement already satisfied: setuptools in /Users/dmpm/anaconda/lib/python3.6/site-packages/setuptools-27.2.0-py3.6.egg (from protobuf>=3.2.0->tensorflow)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/dmpm/anaconda/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: pyyaml in /Users/dmpm/anaconda/lib/python3.6/site-packages (from keras)\r\n",
      "Requirement already satisfied: six in /Users/dmpm/anaconda/lib/python3.6/site-packages (from keras)\r\n",
      "Requirement already satisfied: theano in /Users/dmpm/anaconda/lib/python3.6/site-packages (from keras)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/dmpm/anaconda/lib/python3.6/site-packages (from theano->keras)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/dmpm/anaconda/lib/python3.6/site-packages (from theano->keras)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importa os pacotes\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Garante a reproducividade do código\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Carrega os dados e separa as variáveis independentes (x) e dependente (y)\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter = \",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separa os dados entre treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.33, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos em Keras são definidos como uma sequência de camadas. Isto facilita a criação do modelo, bastando inserir uma camada por vez até que estejamos satisfeitos com a topologia da rede. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira coisa a se fazer é garantir que a camada de entrada tem o número correto de inputs. Isto pode ser especificado enquanto criando a primeira camada com o argumento ‘input_dim’,  atribuindo-lhe 8, para o variáveis de entrada. No exemplo a estrutura de rede é fully-connected com 3 camadas. Isto é, todos os neurônios se comunicam antes da saída."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós podemos especificar o número de neurônios na camada como primeiro argumento, o método de inicialização como segundo argmento sendo ‘init’ e especificar a função de ativação utilizando o argumento ‘activation’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, nós inicializamos o peso da rede para um pequeno número randômico gerado a partir de uma distribuição uniforme (‘uniform’), entre 0 e 0.05, nesse caso, porque esse é o peso padrão da distribuição uniforme no Keras. Uma alternativa tradicional seria o ‘normal’, gerando assim pequenos números randômicos a partir de uma distribuição gaussiana. Também será usada a função de ativação ‘relu’ nas primeiras duas camadas e a função sigmoide na camada de saída. O resultado deverá ser algo entre 0 e 1 com um threshold  padrão de 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construindo o código, você pode notar que a primeira camada tem 12 neurônios e espera 8 variáveis de entrada. A segunda camada  possui 8 neurônios e finalmente a saída tem 1 neurônio fazendo a predição da classe alvo (tendência a desenvolver diabetes ou não)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmpm/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/dmpm/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/dmpm/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Cria o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, init = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(8, init = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid', init = 'uniform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A compilação do modelo usa uma eficiente biblioteca numérica de backend, como Theano or TensorFlow. O backend automaticamente escolhe o melhor caminho para representar a rede e fazer predições.\n",
    "\n",
    "Será necessário em algum momento especificar a função de perda para avaliar os pesos. Nesse exemplo foi definido o uso da função de perda logarítmica, definido em Keras como “binary_crossentropy”. Também é utilizado o algoritmo Stochastic Gradient Descent para otimização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compila o modelo\n",
    "model.compile(loss = 'binary_crossentropy', \n",
    "              optimizer = SGD(lr = 0.01, momentum = 0.9, nesterov = True), \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 0s - loss: 0.6641 - acc: 0.6510     \n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s - loss: 0.6443 - acc: 0.6510     \n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s - loss: 0.6432 - acc: 0.6510     \n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s - loss: 0.6489 - acc: 0.6510     \n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s - loss: 0.6429 - acc: 0.6510     \n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s - loss: 0.6305 - acc: 0.6536     \n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s - loss: 0.6135 - acc: 0.6667     \n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s - loss: 0.6270 - acc: 0.6719     \n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s - loss: 0.6342 - acc: 0.6563     \n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s - loss: 0.6186 - acc: 0.6706     \n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s - loss: 0.6194 - acc: 0.6758     \n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s - loss: 0.6351 - acc: 0.6641     \n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s - loss: 0.6125 - acc: 0.6914     \n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s - loss: 0.6522 - acc: 0.6484     \n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s - loss: 0.6472 - acc: 0.6510     \n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s - loss: 0.6439 - acc: 0.6510     \n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s - loss: 0.6417 - acc: 0.6510     \n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s - loss: 0.6383 - acc: 0.6510     \n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s - loss: 0.6308 - acc: 0.6510     \n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s - loss: 0.6298 - acc: 0.6510     \n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s - loss: 0.6298 - acc: 0.6510     \n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s - loss: 0.6203 - acc: 0.6510     \n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s - loss: 0.6485 - acc: 0.6510     \n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s - loss: 0.6302 - acc: 0.6510     \n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s - loss: 0.6531 - acc: 0.6510     \n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s - loss: 0.6416 - acc: 0.6510     \n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s - loss: 0.6395 - acc: 0.6510     \n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s - loss: 0.6441 - acc: 0.6510     \n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s - loss: 0.6460 - acc: 0.6510     \n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s - loss: 0.6467 - acc: 0.6510     \n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s - loss: 0.6468 - acc: 0.6510     \n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s - loss: 0.6468 - acc: 0.6510     \n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s - loss: 0.6482 - acc: 0.6510     \n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s - loss: 0.6472 - acc: 0.6510     \n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s - loss: 0.6483 - acc: 0.6510     \n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s - loss: 0.6465 - acc: 0.6510     \n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s - loss: 0.6471 - acc: 0.6510     \n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s - loss: 0.6472 - acc: 0.6510     \n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s - loss: 0.6476 - acc: 0.6510     \n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s - loss: 0.6466 - acc: 0.6510     \n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s - loss: 0.6475 - acc: 0.6510     \n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s - loss: 0.6471 - acc: 0.6510     \n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s - loss: 0.6465 - acc: 0.6510     \n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s - loss: 0.6468 - acc: 0.6510     \n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s - loss: 0.6463 - acc: 0.6510     \n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s - loss: 0.6465 - acc: 0.6510     \n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s - loss: 0.6467 - acc: 0.6510     \n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s - loss: 0.6467 - acc: 0.6510     \n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s - loss: 0.6471 - acc: 0.6510     \n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s - loss: 0.6463 - acc: 0.6510     \n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s - loss: 0.6471 - acc: 0.6510     \n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s - loss: 0.6465 - acc: 0.6510     \n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s - loss: 0.6474 - acc: 0.6510     \n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s - loss: 0.6466 - acc: 0.6510     \n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s - loss: 0.6471 - acc: 0.6510     \n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s - loss: 0.6466 - acc: 0.6510     \n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s - loss: 0.6471 - acc: 0.6510     \n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s - loss: 0.6463 - acc: 0.6510     \n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s - loss: 0.6467 - acc: 0.6510     \n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s - loss: 0.6465 - acc: 0.6510     \n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s - loss: 0.6466 - acc: 0.6510     \n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s - loss: 0.6483 - acc: 0.6510     \n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s - loss: 0.6466 - acc: 0.6510     \n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s - loss: 0.6464 - acc: 0.6510     \n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s - loss: 0.6475 - acc: 0.6510     \n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s - loss: 0.6480 - acc: 0.6510     \n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s - loss: 0.6464 - acc: 0.6510     \n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s - loss: 0.6478 - acc: 0.6510     \n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s - loss: 0.6470 - acc: 0.6510     \n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s - loss: 0.6468 - acc: 0.6510     \n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s - loss: 0.6470 - acc: 0.6510     \n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s - loss: 0.6472 - acc: 0.6510     \n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s - loss: 0.6468 - acc: 0.6510     \n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s - loss: 0.6464 - acc: 0.6510     \n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s - loss: 0.6465 - acc: 0.6510     \n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s - loss: 0.6468 - acc: 0.6510     \n",
      "Epoch 89/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s - loss: 0.6464 - acc: 0.6510     \n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s - loss: 0.6462 - acc: 0.6510     \n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s - loss: 0.6467 - acc: 0.6510     \n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s - loss: 0.6467 - acc: 0.6510     \n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s - loss: 0.6467 - acc: 0.6510     \n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s - loss: 0.6468 - acc: 0.6510     \n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s - loss: 0.6466 - acc: 0.6510     \n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s - loss: 0.6466 - acc: 0.6510     \n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s - loss: 0.6468 - acc: 0.6510     \n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s - loss: 0.6468 - acc: 0.6510     \n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s - loss: 0.6464 - acc: 0.6510     \n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s - loss: 0.6476 - acc: 0.6510     \n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s - loss: 0.6479 - acc: 0.6510     \n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s - loss: 0.6475 - acc: 0.6510     \n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s - loss: 0.6478 - acc: 0.6510     \n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s - loss: 0.6467 - acc: 0.6510     \n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s - loss: 0.6464 - acc: 0.6510     \n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s - loss: 0.6466 - acc: 0.6510     \n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s - loss: 0.6465 - acc: 0.6510     \n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s - loss: 0.6464 - acc: 0.6510     \n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s - loss: 0.6487 - acc: 0.6510     \n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s - loss: 0.6471 - acc: 0.6510     \n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s - loss: 0.6468 - acc: 0.6510     \n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s - loss: 0.6472 - acc: 0.6510     \n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s - loss: 0.6473 - acc: 0.6510     \n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s - loss: 0.6471 - acc: 0.6510     \n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s - loss: 0.6465 - acc: 0.6510     \n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s - loss: 0.6470 - acc: 0.6510     \n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s - loss: 0.6481 - acc: 0.6510     \n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s - loss: 0.6479 - acc: 0.6510     \n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s - loss: 0.6467 - acc: 0.6510     \n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s - loss: 0.6463 - acc: 0.6510     \n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s - loss: 0.6468 - acc: 0.6510     \n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s - loss: 0.6471 - acc: 0.6510     \n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s - loss: 0.6466 - acc: 0.6510     \n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s - loss: 0.6470 - acc: 0.6510     \n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s - loss: 0.6466 - acc: 0.6510     \n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s - loss: 0.6471 - acc: 0.6510     \n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s - loss: 0.6470 - acc: 0.6510     \n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s - loss: 0.6466 - acc: 0.6510     \n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s - loss: 0.6472 - acc: 0.6510     \n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s - loss: 0.6486 - acc: 0.6510     \n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s - loss: 0.6467 - acc: 0.6510     \n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s - loss: 0.6479 - acc: 0.6510     \n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s - loss: 0.6464 - acc: 0.6510     \n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s - loss: 0.6465 - acc: 0.6510     \n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s - loss: 0.6475 - acc: 0.6510     \n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s - loss: 0.6475 - acc: 0.6510     \n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s - loss: 0.6467 - acc: 0.6510     \n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s - loss: 0.6464 - acc: 0.6510     \n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s - loss: 0.6464 - acc: 0.6510     \n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s - loss: 0.6467 - acc: 0.6510     \n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s - loss: 0.6482 - acc: 0.6510     \n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s - loss: 0.6469 - acc: 0.6510     \n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s - loss: 0.6465 - acc: 0.6510     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b9c0ef0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executa o modelo e valida nos mesmos dados em que foi criado (treino)\n",
    "model.fit(X, Y, epochs = 150, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utlizar outro algoritmo para otimização, como o Gradient descent adm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compila o modelo com outro otimizador\n",
    "model.compile(loss = 'binary_crossentropy', \n",
    "              optimizer = 'adam', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 25/150\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.6534 - acc: 0.640 - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s - loss: 0.6461 - acc: 0.6510     \n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s - loss: 0.6460 - acc: 0.6510     \n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 88/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s - loss: 0.6460 - acc: 0.6510     \n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s - loss: 0.6460 - acc: 0.6510     \n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s - loss: 0.6459 - acc: 0.6510     \n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s - loss: 0.6458 - acc: 0.6510     \n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s - loss: 0.6457 - acc: 0.6510     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11bddfda0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executa o modelo e valida nos mesmos dados em que foi criado (treino)\n",
    "model.fit(X, Y, epochs = 150, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.24548283,  0.01882353, -0.02652038, -0.05760321,  0.01449152,\n",
       "         -0.08701063, -0.04603405, -0.03367117, -0.02472733, -0.05372381,\n",
       "          0.05214783, -0.035793  ],\n",
       "        [ 0.27082995, -0.03511642, -0.07947718, -0.45060286, -0.01615932,\n",
       "         -0.51280266, -0.10528696, -0.31216311,  0.03363472, -0.11666528,\n",
       "         -0.6973021 , -0.01599389],\n",
       "        [-1.38022661, -0.00493143,  0.02851148,  0.12986064, -0.00596693,\n",
       "          0.35465357, -0.08251435,  0.1227138 , -0.09167561,  0.07863504,\n",
       "         -1.22630298, -0.04335348],\n",
       "        [-0.30186391, -0.01141974, -0.03252077, -0.00611984,  0.01156154,\n",
       "          0.10826928, -0.01508366,  0.0424165 , -0.04199095, -0.03025991,\n",
       "         -0.36759257,  0.02202759],\n",
       "        [-0.51083142, -0.00778842, -0.05383245, -0.06956745, -0.02668305,\n",
       "         -0.08669829,  0.03125232,  0.0304867 , -0.11787476, -0.02753801,\n",
       "          0.27527177, -0.0114973 ],\n",
       "        [-0.13076825, -0.01866753, -0.00713822, -0.05198315, -0.02373129,\n",
       "          0.07474324, -0.06450478, -0.03228798,  0.00953635, -0.03272282,\n",
       "         -0.49771059,  0.01339575],\n",
       "        [ 0.00451895,  0.00657737, -0.03795296, -0.03606074,  0.04034   ,\n",
       "          0.00306654,  0.02057223, -0.02508977, -0.0211938 , -0.00635461,\n",
       "          0.01734955,  0.00195978],\n",
       "        [-0.25193167, -0.04497098,  0.01795819, -0.05951577,  0.02301932,\n",
       "         -0.14915483, -0.00388205, -0.06688887, -0.02240846,  0.02860355,\n",
       "         -0.1961616 , -0.00844307]], dtype=float32),\n",
       " array([-0.05575911,  0.        ,  0.00086457,  0.00536307, -0.00023078,\n",
       "         0.00996667, -0.00221656,  0.00410106, -0.00094343,  0.00176759,\n",
       "        -0.02024473,  0.        ], dtype=float32),\n",
       " array([[-0.00744815, -0.12674746, -0.05991616, -0.03439363, -0.09819476,\n",
       "         -0.00266702, -0.0463375 , -0.28268582],\n",
       "        [-0.03758268,  0.04086727,  0.01231974,  0.03475353, -0.01534702,\n",
       "         -0.04859821, -0.03785787,  0.04478196],\n",
       "        [-0.04002359,  0.0039129 ,  0.00254838,  0.01701159, -0.04829309,\n",
       "          0.03791278,  0.03673293,  0.03501737],\n",
       "        [-0.04610134,  0.02786104, -0.02309364,  0.01318476,  0.00963604,\n",
       "          0.00535786, -0.01183467,  0.0456982 ],\n",
       "        [-0.04253895,  0.01847911, -0.01784568,  0.02777005,  0.00480926,\n",
       "          0.00909333, -0.04472386, -0.03149626],\n",
       "        [-0.02880509, -0.01362098, -0.0197626 , -0.02377122, -0.0063557 ,\n",
       "         -0.00493845, -0.14578731, -0.08306751],\n",
       "        [-0.0325921 , -0.03243022, -0.04664338, -0.03454573, -0.06112808,\n",
       "         -0.01466941, -0.00079278, -0.07404875],\n",
       "        [-0.00419129, -0.02972736, -0.02963216, -0.04869335, -0.01075174,\n",
       "         -0.05733459,  0.0217231 ,  0.04549593],\n",
       "        [-0.00960886, -0.02287217, -0.04376341,  0.03679417, -0.01333728,\n",
       "         -0.03588819, -0.01146036, -0.01548026],\n",
       "        [-0.01022706,  0.01009181,  0.005302  ,  0.01953587, -0.03688353,\n",
       "          0.01149145, -0.03968846,  0.00337008],\n",
       "        [-0.04593505, -0.03621796, -0.08533319, -0.04607156, -0.11218236,\n",
       "         -0.0423584 , -0.05154049, -0.19408309],\n",
       "        [ 0.00404942,  0.04975183,  0.00692933,  0.01959943, -0.04208268,\n",
       "         -0.02310252, -0.02862998,  0.02998039]], dtype=float32),\n",
       " array([-0.00128218,  0.13515806, -0.05599773, -0.00201888,  0.11380934,\n",
       "        -0.00526401, -0.07686555,  0.62166083], dtype=float32),\n",
       " array([[-0.00465363],\n",
       "        [-0.13113552],\n",
       "        [-0.07552994],\n",
       "        [ 0.01677574],\n",
       "        [-0.10018016],\n",
       "        [ 0.02998348],\n",
       "        [-0.04466214],\n",
       "        [-0.59814823]], dtype=float32),\n",
       " array([-0.25101787], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O treinamento da rede neural foi feita sobre o conjunto completo de dados e a performance da rede neural pode ser avaliada no mesmo conjunto de dados, o que nos dará uma boa ideia do quão bem modelada foi a rede. Utiliza-se a função evaluate() no modelo, passando o mesmo número de inputs e outputs usados no treinamento. Isto gerará uma predição para cada entrada e saída e coletará pontuação, incluindo média de perda e qualquer métrica que tenha sido configurada, como a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/768 [>.............................] - ETA: 0sacc: 65.10%\n"
     ]
    }
   ],
   "source": [
    "# Avalia os resultados do modelo\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6331 - val_acc: 0.6732\n",
      "Epoch 2/150\n",
      "514/514 [==============================] - 0s - loss: 0.6520 - acc: 0.6401 - val_loss: 0.6334 - val_acc: 0.6732\n",
      "Epoch 3/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6333 - val_acc: 0.6732\n",
      "Epoch 4/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6335 - val_acc: 0.6732\n",
      "Epoch 5/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6335 - val_acc: 0.6732\n",
      "Epoch 6/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6335 - val_acc: 0.6732\n",
      "Epoch 7/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6335 - val_acc: 0.6732\n",
      "Epoch 8/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6337 - val_acc: 0.6732\n",
      "Epoch 9/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6336 - val_acc: 0.6732\n",
      "Epoch 10/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6338 - val_acc: 0.6732\n",
      "Epoch 11/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6337 - val_acc: 0.6732\n",
      "Epoch 12/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 13/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 14/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 15/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 16/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 17/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.67320.65\n",
      "Epoch 18/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 19/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 20/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 21/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 22/150\n",
      "514/514 [==============================] - 0s - loss: 0.6520 - acc: 0.6401 - val_loss: 0.6338 - val_acc: 0.6732\n",
      "Epoch 23/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 24/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 25/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 26/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 27/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 28/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 29/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 30/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6345 - val_acc: 0.6732\n",
      "Epoch 31/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 32/150\n",
      "514/514 [==============================] - ETA: 0s - loss: 0.6446 - acc: 0.650 - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 33/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 34/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 35/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 36/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 37/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 38/150\n",
      "514/514 [==============================] - 0s - loss: 0.6520 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 39/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 40/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 41/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6337 - val_acc: 0.6732\n",
      "Epoch 42/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 43/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 44/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 45/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 46/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 47/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 48/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 49/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 50/150\n",
      "514/514 [==============================] - 0s - loss: 0.6516 - acc: 0.6401 - val_loss: 0.6338 - val_acc: 0.6732\n",
      "Epoch 51/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 52/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6338 - val_acc: 0.6732\n",
      "Epoch 53/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 54/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6338 - val_acc: 0.6732\n",
      "Epoch 55/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 56/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 57/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 58/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 59/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 60/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 61/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 62/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 63/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 64/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 65/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 66/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 67/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 68/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 69/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 70/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 71/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 72/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 73/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 74/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 75/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 76/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 77/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 78/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 79/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 80/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 81/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 82/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 83/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 84/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 85/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 86/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 87/150\n",
      "514/514 [==============================] - 0s - loss: 0.6516 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 88/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 89/150\n",
      "514/514 [==============================] - 0s - loss: 0.6516 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 90/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 91/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 92/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 93/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 94/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 95/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 96/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 97/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 98/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 99/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 100/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 101/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 102/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6345 - val_acc: 0.6732\n",
      "Epoch 103/150\n",
      "514/514 [==============================] - 0s - loss: 0.6516 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 104/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6339 - val_acc: 0.6732\n",
      "Epoch 105/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 106/150\n",
      "514/514 [==============================] - 0s - loss: 0.6516 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 107/150\n",
      "514/514 [==============================] - 0s - loss: 0.6516 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 108/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 109/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 110/150\n",
      "514/514 [==============================] - 0s - loss: 0.6516 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 111/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6344 - val_acc: 0.6732\n",
      "Epoch 112/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 113/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 114/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 115/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 116/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 117/150\n",
      "514/514 [==============================] - 0s - loss: 0.6516 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 118/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 119/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 120/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 121/150\n",
      "514/514 [==============================] - 0s - loss: 0.6516 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 122/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 123/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 124/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 125/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 126/150\n",
      "514/514 [==============================] - 0s - loss: 0.6516 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 127/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 128/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 129/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 130/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 131/150\n",
      "514/514 [==============================] - 0s - loss: 0.6516 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 132/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 133/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 134/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 135/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 136/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 137/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 138/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 139/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6340 - val_acc: 0.6732\n",
      "Epoch 140/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 141/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 142/150\n",
      "514/514 [==============================] - 0s - loss: 0.6516 - acc: 0.6401 - val_loss: 0.6343 - val_acc: 0.6732\n",
      "Epoch 143/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6346 - val_acc: 0.6732\n",
      "Epoch 144/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 145/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n",
      "Epoch 146/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 147/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 148/150\n",
      "514/514 [==============================] - 0s - loss: 0.6517 - acc: 0.6401 - val_loss: 0.6342 - val_acc: 0.6732\n",
      "Epoch 149/150\n",
      "514/514 [==============================] - 0s - loss: 0.6519 - acc: 0.6401 - val_loss: 0.6346 - val_acc: 0.6732\n",
      "Epoch 150/150\n",
      "514/514 [==============================] - 0s - loss: 0.6518 - acc: 0.6401 - val_loss: 0.6341 - val_acc: 0.6732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11bfaada0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executa o modelo e faz validação em um conjunto de dados separado automaticamente para teste\n",
    "model.fit(X, Y, validation_split = 0.33, epochs = 150, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/150\n",
      "514/514 [==============================] - 0s - loss: 0.6411 - acc: 0.6576 - val_loss: 0.6556 - val_acc: 0.6378\n",
      "Epoch 2/150\n",
      "514/514 [==============================] - 0s - loss: 0.6410 - acc: 0.6576 - val_loss: 0.6558 - val_acc: 0.6378\n",
      "Epoch 3/150\n",
      "514/514 [==============================] - 0s - loss: 0.6407 - acc: 0.6576 - val_loss: 0.6559 - val_acc: 0.6378\n",
      "Epoch 4/150\n",
      "514/514 [==============================] - 0s - loss: 0.6406 - acc: 0.6576 - val_loss: 0.6561 - val_acc: 0.6378\n",
      "Epoch 5/150\n",
      "514/514 [==============================] - 0s - loss: 0.6407 - acc: 0.6576 - val_loss: 0.6560 - val_acc: 0.6378\n",
      "Epoch 6/150\n",
      "514/514 [==============================] - 0s - loss: 0.6405 - acc: 0.6576 - val_loss: 0.6564 - val_acc: 0.6378\n",
      "Epoch 7/150\n",
      "514/514 [==============================] - 0s - loss: 0.6406 - acc: 0.6576 - val_loss: 0.6562 - val_acc: 0.6378\n",
      "Epoch 8/150\n",
      "514/514 [==============================] - 0s - loss: 0.6407 - acc: 0.6576 - val_loss: 0.6565 - val_acc: 0.6378\n",
      "Epoch 9/150\n",
      "514/514 [==============================] - 0s - loss: 0.6405 - acc: 0.6576 - val_loss: 0.6567 - val_acc: 0.6378\n",
      "Epoch 10/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6566 - val_acc: 0.6378\n",
      "Epoch 11/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6567 - val_acc: 0.6378\n",
      "Epoch 12/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6567 - val_acc: 0.6378\n",
      "Epoch 13/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6567 - val_acc: 0.6378\n",
      "Epoch 14/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 15/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 16/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6567 - val_acc: 0.6378\n",
      "Epoch 17/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 18/150\n",
      "514/514 [==============================] - 0s - loss: 0.6405 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 19/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 20/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 21/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 22/150\n",
      "514/514 [==============================] - 0s - loss: 0.6405 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 23/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6567 - val_acc: 0.6378\n",
      "Epoch 24/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 25/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 26/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6567 - val_acc: 0.6378\n",
      "Epoch 27/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 28/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6567 - val_acc: 0.6378\n",
      "Epoch 29/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 30/150\n",
      "514/514 [==============================] - 0s - loss: 0.6406 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 31/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 32/150\n",
      "514/514 [==============================] - 0s - loss: 0.6407 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 33/150\n",
      "514/514 [==============================] - 0s - loss: 0.6405 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n",
      "Epoch 34/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 35/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 36/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 37/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 38/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 39/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 40/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 41/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 42/150\n",
      "514/514 [==============================] - 0s - loss: 0.6406 - acc: 0.6576 - val_loss: 0.6573 - val_acc: 0.6378\n",
      "Epoch 43/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n",
      "Epoch 44/150\n",
      "514/514 [==============================] - 0s - loss: 0.6405 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 45/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 46/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 47/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n",
      "Epoch 48/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 49/150\n",
      "514/514 [==============================] - 0s - loss: 0.6405 - acc: 0.6576 - val_loss: 0.6567 - val_acc: 0.6378\n",
      "Epoch 50/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6567 - val_acc: 0.6378\n",
      "Epoch 51/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 52/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 53/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 54/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 55/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 56/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 57/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 58/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 59/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 60/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 61/150\n",
      "514/514 [==============================] - 0s - loss: 0.6405 - acc: 0.6576 - val_loss: 0.6573 - val_acc: 0.6378\n",
      "Epoch 62/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 63/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 64/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6567 - val_acc: 0.6378\n",
      "Epoch 65/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 66/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 67/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 68/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 69/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n",
      "Epoch 70/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n",
      "Epoch 71/150\n",
      "514/514 [==============================] - 0s - loss: 0.6405 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 72/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 73/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 74/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6567 - val_acc: 0.6378\n",
      "Epoch 75/150\n",
      "514/514 [==============================] - 0s - loss: 0.6406 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 76/150\n",
      "514/514 [==============================] - 0s - loss: 0.6402 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 77/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 78/150\n",
      "514/514 [==============================] - 0s - loss: 0.6405 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 79/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 80/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 81/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 82/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 83/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 84/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n",
      "Epoch 85/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 86/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n",
      "Epoch 87/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 88/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 89/150\n",
      "514/514 [==============================] - 0s - loss: 0.6405 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 90/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 91/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 92/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n",
      "Epoch 93/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 94/150\n",
      "514/514 [==============================] - 0s - loss: 0.6405 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 95/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 96/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 97/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n",
      "Epoch 98/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 99/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 100/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 101/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 102/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6568 - val_acc: 0.6378\n",
      "Epoch 103/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n",
      "Epoch 104/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 105/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 106/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 107/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 108/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 109/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 110/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 111/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 112/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6573 - val_acc: 0.6378\n",
      "Epoch 113/150\n",
      "514/514 [==============================] - 0s - loss: 0.6407 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 114/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n",
      "Epoch 115/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 116/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n",
      "Epoch 117/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 118/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6573 - val_acc: 0.6378\n",
      "Epoch 119/150\n",
      "514/514 [==============================] - 0s - loss: 0.6402 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 120/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6573 - val_acc: 0.6378\n",
      "Epoch 121/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6574 - val_acc: 0.6378\n",
      "Epoch 122/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 123/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 124/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6573 - val_acc: 0.6378\n",
      "Epoch 125/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6573 - val_acc: 0.6378\n",
      "Epoch 126/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 127/150\n",
      "514/514 [==============================] - 0s - loss: 0.6406 - acc: 0.6576 - val_loss: 0.6574 - val_acc: 0.6378\n",
      "Epoch 128/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 129/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 130/150\n",
      "514/514 [==============================] - 0s - loss: 0.6402 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 131/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6573 - val_acc: 0.6378\n",
      "Epoch 132/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6573 - val_acc: 0.6378\n",
      "Epoch 133/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 134/150\n",
      "514/514 [==============================] - 0s - loss: 0.6402 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 135/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 136/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n",
      "Epoch 137/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 138/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 139/150\n",
      "514/514 [==============================] - 0s - loss: 0.6402 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 140/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 141/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6569 - val_acc: 0.6378\n",
      "Epoch 142/150\n",
      "514/514 [==============================] - 0s - loss: 0.6402 - acc: 0.6576 - val_loss: 0.6570 - val_acc: 0.6378\n",
      "Epoch 143/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6573 - val_acc: 0.6378\n",
      "Epoch 144/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6571 - val_acc: 0.6378\n",
      "Epoch 145/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6574 - val_acc: 0.6378\n",
      "Epoch 146/150\n",
      "514/514 [==============================] - 0s - loss: 0.6402 - acc: 0.6576 - val_loss: 0.6574 - val_acc: 0.6378\n",
      "Epoch 147/150\n",
      "514/514 [==============================] - 0s - loss: 0.6404 - acc: 0.6576 - val_loss: 0.6573 - val_acc: 0.6378\n",
      "Epoch 148/150\n",
      "514/514 [==============================] - 0s - loss: 0.6402 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n",
      "Epoch 149/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n",
      "Epoch 150/150\n",
      "514/514 [==============================] - 0s - loss: 0.6403 - acc: 0.6576 - val_loss: 0.6572 - val_acc: 0.6378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11be29cf8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executa o modelo e faz validação em um conjunto de dados separado manualmente para teste\n",
    "model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs = 150, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obrigado - Data Science Academy - <a href=http://facebook.com/dsacademy>facebook.com/dsacademybr</a>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
